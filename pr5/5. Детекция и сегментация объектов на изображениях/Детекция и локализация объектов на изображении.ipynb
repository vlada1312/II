{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"iZULaGX7_H1u"},"source":["# Детекция и локализация объектов на изображении.\n"]},{"cell_type":"markdown","source":["\n","На прошлых занятиях мы говорили про классификацию (распознавание) изображений. Мы подавали на вход нейронной сети некоторое изображение, а она определяла, что на нем нарисовано.\n","\n","Но ведь может быть и так, что  на одном изображении нарисовано несколько объектов вместе, например, котик и собачка. Что же в таком случае определит нейронная сеть? Проверьте самостоятельно."],"metadata":{"id":"yG-Xp1xwB0TD"}},{"cell_type":"markdown","source":["\n","\n","Если объектов на изображении несколько, то те архитектуры, которыми мы пользовались ранее для классификации, нам не помогут, нужны другие подходы.\n","\n","Самое простое, что можно здесь придумать - а давайте разобьем изображение на отдельные окошки и будем распознавать только то, что содержится в окошке, а не все изображение целиком. Тогда для каждого окошка нейронная сеть сообщит нам, какой объект в нем нарисован. Потом мы объединим показания из окошек, если, например, в двух близкорасположенных окошках нарисована кошка, то, наверное, это одна и та же кошка.\n","\n","Объекты на изображении могут быть разного размера. Если оно получено путем фотографирования, то близкорасположенные объекты на фотографии больше, чем далекие. Значит нам надо перебирать не только окошки с разным положением, но и с разным масштабом.\n","\n","Окошки, на которые мы разбиваем изображение, могут быть и пересекающиеся, наверное, для тех окошек, в которые попадает объект целиком, нейронная сеть даст большой уровень уверенности распознавания. А для тех, в которых попадает только часть объекта, этот уровень будет маленьким. Тогда сравнивая уровни уверенности для разных окошек, можем выбрать такое, для которого уровень больше и считать его окошком, содержащим распознанный объект. Получается, мы не только распознали каждый объект на изображении, но и нашли окошки, их содержащие.\n","\n","Процесс, когда мы рассчитываем положение окошка, содержащего объект, называют **локализация** (localization), а процесс, когда мы находим такие объекты (с окошками) на изображении - **детекция** (детектирование, detection) объектов. Это задачи похожие на распознавание, но отличаются тем, что кроме указания класса, надо сообщить и окошко, в котором содержится объект. Окошки обычно прямоугольные, мы можем задать их координатами, скажем, левого верхнего и нижнего правого углов, или координатами центра и шириной и высотой.\n","\n","Более сложный вариант задачи, когда кроме окошка надо указать, какие именно пиксели окошка относятся к объекту, а какие нет - называют (объектовой) **сегментацией** (instance segmentation).\n","\n","![img](https://drive.google.com/uc?id=1_9HaQzJQgv7iAFWVK1Z71JgrZHjMmiHG)\n","\n","\n","\n","Есть две идеи работы с такими окошками-кандидатами на проверку:\n","\n","- использовать некоторый алгоритм или обучать нейронную сеть выбору положения и размера окошек (сеть SSD и семейство сетей R-CNN);\n","- выбрать положение и размер окошек заранее (сеть YOLO) и проверять есть ли там объект, уточняя положение окошка при необходимости.\n","\n","Первый случай дает потенциально точность, второй - быстроту.\n","\n","В обоих случаях логично работать не с самими изображениями, а с их картами признаков, полученными после прохождения изображения через какую-нибудь нейронную сеть классификации, такую сеть называют **основой** (backbone).\n","\n","\n"],"metadata":{"id":"sZupeq20CEr1"}},{"cell_type":"markdown","metadata":{"id":"_-Y1YhMs0DEL"},"source":["## Оценка похожести окошек. IoU.\n","\n","Как сравнивать классы мы уже знаем и делали это. Но как сравнить окошки, какое из них лучше, какое хуже?\n","\n","Пусть есть два окошка, настоящее и предсказанное нами. Когда они полностью совпадают это очень хорошо. Когда не пересекаются - очень плохо. Когда пересекаются частично это лучше, чем если вообще не совпадают. Но и размер окошек тоже важен, если одно маленькое и находится внутри другого, то оно верно показывает положение объекта, но неверно его размер. И такие случаи нужно предусмотреть.\n","\n","Для сравнения окошек используют величину IoU (Intersect over Union, пересечение над объединением), которая считается так:\n","- находят площадь пересечения двух окошек\n","- и делят это на площадь объединения двух окошек.\n","\n","![img](https://drive.google.com/uc?id=1SBd9_iZj38eawzTEpG15rDKTfgVrhNC1)\n","\n","Проверьте, что действительно выполняются желаемые нами свойства:\n","- если окошки совпадают, пересечение и объединение одинаковы и IoU=1,\n","- если окошки не пересекаются, то площадь пересечения равна 0 и IoU=0.\n","- если одно окошко внутри другого, или они частично пересекаются то 0 < IoU < 1\n","\n","Функция ошибки для минимизации это 1-IoU.\n","\n","Но тут есть проблема, если окошки не пересекаются вообще, то мы никак неузнаем, как менять параметры сети, чтобы их сблизить, ведь производная будет 0. Надо добавить дополнительные члены в функцию ошибки, которые показывают дальность окошек друг от друга. Также надо учесть разницу в отношении сторон окошек. Все это можно сделать, но, конечно, это усложнит формулы для вычисления функции ошибки (мы не будем приводить из здесь).\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","source":["# Заключение\n","Подходы к детекции объектов на изображении разнообразны. Упомянем сети семейства R-CNN (Region-based CNN), но познакомимся с ними в теме про сегментацию.\n","\n","Посмотреть более современные решения, результаты соревнований по детекции можно [здесь](https://paperswithcode.com/task/object-detection)."],"metadata":{"id":"oVPMOT7eVEV7"}},{"cell_type":"markdown","metadata":{"id":"EigIYiPQdleo"},"source":["# Ссылки\n","\n","Использованы материалы:\n","- https://jonathan-hui.medium.com/yolov4-c9901eaa8e61\n","- https://towardsdatascience.com/understanding-ssd-multibox-real-time-object-detection-in-deep-learning-495ef744fab\n","- https://github.com/pjreddie/darknet/issues/1439\n","- https://github.com/AlexeyAB/darknet/\n","\n","- https://colab.research.google.com/github/d2l-ai/d2l-en-colab/blob/master/chapter_computer-vision/rcnn.ipynb\n","- https://colab.research.google.com/github/tensorflow/models/blob/master/research/object_detection/colab_tutorials/context_rcnn_tutorial.ipynb\n","- https://colab.research.google.com/github/google/eng-edu/blob/master/ml/pc/exercises/image_classification_part3.ipynb#scrollTo=YHK6DyunSbs4\n","\n","- https://d2l.ai/chapter_computer-vision/ssd.html\n","- https://d2l.ai/chapter_computer-vision/rcnn.html\n"]},{"cell_type":"code","source":[],"metadata":{"id":"nirGgLfFSQEO"},"execution_count":null,"outputs":[]}]}